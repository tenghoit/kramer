⭐ What LLMs Actually Process — Tokens
LLMs don’t read words; they read tokens.
Tokenizer splits text into subwords, e.g.:
“Out walking!” → [“out”, “walk”, “ing”, “!”]
Token vocabularies are small (~50k) compared to total word counts.
Tokens often align with morphemes, giving meaningful semantic chunks.
⭐ Positional Encoding — Adding Order
Transformers read everything in parallel, unlike RNNs.
They need a way to represent sequence order.
Positional embeddings encode where each token sits in the sequence.
Without positional encoding, the model would treat phrases as unordered bags of words.
⭐ Generating Text — Next-Token Prediction
Main prediction objective: guess the next token based on context.
Softmax converts logits → probabilities that sum to 1.
Temperature controls determinism:
Low temperature → predictable
High temperature → creative, diverse
⭐ Controlling Generation: Top-k & Top-p
Top-k sampling: restrict next-token candidates to top k probabilities.
Top-p (nucleus) sampling: use the smallest set of tokens whose cumulative probability ≥ p.
Combined with temperature, these shape the model’s creativity and coherence.
Used in chatbots, creative writing, story generation, etc.
⭐ Attention — The Core Idea
The meaning of a word depends on context.
Attention assigns scores of relevance between tokens.
Example: “The cat ate because it was hungry.”
→ “it” should attend to “cat,” not “ate.”
This lets Transformers understand long-range dependencies.
⭐ How Transformers Handle Context
Self-attention: every token attends to every other token (including itself).
Supports large context windows — thousands of tokens.
Context-sensitive meaning: “it” means different things depending on sentence.
⭐ Queries, Keys, Values — How Attention Computes Relevance
Each token produces:
Query → What am I looking for?
Key → What information do I have?
Value → The content to pass on if this token is relevant
Example: resolving pronouns
Query("it") → trying to identify referent
Key("cat") → contains semantic info
Value("cat") → meaning forwarded to the next layer
The dot-product of Query·Key gives the attention score.
⭐ Self-Attention — Why It’s Powerful
Captures syntactic, semantic, and long-range relationships.
Computes in parallel → huge speedup vs. RNNs.
Core reason Transformers scale well to large models.
⭐ Multi-Headed Attention
Multiple attention heads allow the model to learn different types of relationships at once.
Example from slides:
Head 1: semantic link (“it” ↔ “cat”)
Head 2: syntactic structure (subject-verb agreement)
Each head processes queries/keys/values in a separate subspace.
Results are concatenated → richer representation.
⭐ Why Multi-Head Attention Matters
Handles different linguistic functions simultaneously.
Improves model expressiveness without huge computational cost.
Essential for capturing layers of meaning (syntax, semantics, discourse).
⭐ Fine-Tuning
Start from a pretrained base model.
Train it further on a domain (medical, legal, tutoring, etc.).
Saves compute & time; base model already knows general language structure.
⭐ RLHF — Reinforcement Learning with Human Feedback
Aligns model behavior with human preferences.
Uses human rankings of outputs to train a reward model.
Model then optimized (PPO, etc.) to produce outputs humans prefer.
Used to make ChatGPT safe, polite, helpful, and follow instructions.
⭐ Shoggoth RLHF Meme (Slide Reference)
The “Shoggoth” meme visualizes:
A giant monstrous LLM (raw pretrained model)
A small friendly smiley mask (the aligned RLHF behavior)
Meaning:
Base models are powerful but unaligned
RLHF acts like a “mask” that shapes interaction behavior
NYT link on slide discusses public perception & alignment concerns.
⭐ Applications of Transformers
Chatbots
Customer service assistants
Translation (especially real-time)
Creative writing & brainstorming
Tutoring and educational tools
⭐ Limitations & Concerns
Context window limit — still bounded (even at 128k+ tokens).
Hallucinations — models invent plausible but incorrect info.
Bias from training data propagates into outputs.
Ethical/environmental concerns: compute cost, misinformation risks.
⭐ Wrap-Up
Transformers revolutionized NLP by introducing attention, enabling parallelism + contextual reasoning.
GPT is a generative model built on Transformer decoder architecture.
Next topics: RAG + agents + deployment considerations.
